{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "835b6358",
   "metadata": {
    "id": "835b6358"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04a73760",
   "metadata": {
    "id": "04a73760"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image # For displaying images in colab jupyter cell\n",
    "from PIL import Image as PilImage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc1fbb",
   "metadata": {
    "id": "9dcc1fbb"
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dfa7da9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1729149007409,
     "user": {
      "displayName": "Caroline Crooks",
      "userId": "10803179327028008482"
     },
     "user_tz": 420
    },
    "id": "5dfa7da9",
    "outputId": "0bc26771-8cee-4adc-d02a-d8a52b612e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Features Shape:  (1311, 128, 128)\n",
      "Testing Targets Shape:  (1311,)\n"
     ]
    }
   ],
   "source": [
    "# Load images\n",
    "\n",
    "# training features/targets where each feature is a greyscale image with shape (512, 512)\n",
    "classes = [\"pituitary\", \"notumor\", \"meningioma\", \"glioma\"]\n",
    "test_folder = \"../data/Testing\"\n",
    "\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "# load image from a folder\n",
    "def load_image(folder_path):\n",
    "    features = []\n",
    "    targets = []\n",
    "    for index, class_label in enumerate(classes):\n",
    "        class_folder = os.path.join(folder_path, class_label)\n",
    "        for img_name in os.listdir(class_folder):\n",
    "            img_path = os.path.join(class_folder, img_name)\n",
    "            #print(img_path)\n",
    "            try:\n",
    "                img = PilImage.open(img_path).convert(\"L\")\n",
    "                img = img.resize((img_height,img_width))\n",
    "                img_array = np.array(img)\n",
    "                features.append(img_array)\n",
    "                targets.append(index)\n",
    "            except Exception as e:\n",
    "                print(\"Error loading image \", e)\n",
    "    return np.array(features), np.array(targets)\n",
    "\n",
    "# load images\n",
    "test_features, test_targets = load_image(test_folder)\n",
    "\n",
    "# shapes of training/testing datasets\n",
    "print(\"Testing Features Shape: \", test_features.shape)\n",
    "print(\"Testing Targets Shape: \", test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac9be3f7",
   "metadata": {
    "id": "ac9be3f7"
   },
   "outputs": [],
   "source": [
    "# perform standard scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# First flatten each image into 512*512 to convert features from 3D -> 2D arrays\n",
    "test_features_flat = test_features.reshape((1311, img_width*img_height))\n",
    "num_testing = 1311\n",
    "# Use standard scaler to scale the flattened images\n",
    "scaler = StandardScaler()\n",
    "test_features = scaler.fit_transform(test_features_flat).reshape((1311, img_width*img_height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c8f2369",
   "metadata": {
    "id": "8c8f2369"
   },
   "outputs": [],
   "source": [
    "# Reshape train/validation/test sets to conform to PyTorch's (N, Channels, Height, Width) standard for CNNs\n",
    "test_features = np.reshape(test_features, (num_testing, 1, img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f42d2-2aca-469e-a2e2-598fe021a11b",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b5eae60-7350-4cba-9301-3e3cabdfcd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # Second convolution layer with 16 out channels, 1 padding\n",
    "        self.cnn1 = torch.nn.Conv2d(in_channels=1, out_channels=16,\n",
    "                              kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # normalization for statbility\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(16)\n",
    "\n",
    "        # size 2 kernel for maxpool\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second convolution layer with 32 out channels, 1 padding\n",
    "        self.cnn2 = torch.nn.Conv2d(in_channels=16, out_channels=32,\n",
    "                              kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # normalization for statbility\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # size 2 kernel for maxpool\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Third convolution layer with 64 out channels, 1 padding\n",
    "        self.cnn3 = torch.nn.Conv2d(in_channels=32, out_channels=64,\n",
    "                              kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # normalization for statbility\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        # size 2 kernel for maxpool\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Fully connected layer that takes the flattened output\n",
    "        self.fc2 = torch.nn.Linear(64 * 16 * 16, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # input image -> conv1 -> relu -> batchnorm -> maxpool1\n",
    "        conv1_out = torch.nn.functional.relu(self.cnn1(x))\n",
    "        pool1_out = self.maxpool1(self.batchnorm1(conv1_out))\n",
    "\n",
    "        # maxpool1 output -> conv2 -> relu -> batchnorm -> maxpool2\n",
    "        conv2_out = torch.nn.functional.relu(self.cnn2(pool1_out))\n",
    "        pool2_out = self.maxpool2(self.batchnorm2(conv2_out))\n",
    "\n",
    "        # maxpool2 output -> conv3 -> relu -> batchnorm -> maxpool3\n",
    "        conv3_out = torch.nn.functional.relu(self.cnn3(pool2_out))\n",
    "        pool3_out = self.maxpool3(self.batchnorm3(conv3_out))\n",
    "\n",
    "        # flatten the maxpool3 output to be used as input into FCN layer\n",
    "        fcn_input = pool3_out.view(pool3_out.size(0), -1)\n",
    "\n",
    "        # Use the raw output of the fully connected layer as the final output\n",
    "        out = self.fc2(fcn_input)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9624830",
   "metadata": {
    "id": "b9624830"
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29b27103-8a8d-400e-b39d-f8f2b1c01fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carol\\AppData\\Local\\Temp\\ipykernel_23876\\639422568.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"../model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (cnn1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (cnn2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (cnn3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc2): Linear(in_features=16384, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNModel()\n",
    "model.load_state_dict(torch.load(\"../model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf9a22e",
   "metadata": {
    "id": "adf9a22e"
   },
   "source": [
    "## Visualize & Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee8589b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1537,
     "status": "ok",
     "timestamp": 1729149517360,
     "user": {
      "displayName": "Caroline Crooks",
      "userId": "10803179327028008482"
     },
     "user_tz": 420
    },
    "id": "ee8589b6",
    "outputId": "eb6e0f7f-eeae-464b-941a-74b4ef32ebf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 96.26%\n"
     ]
    }
   ],
   "source": [
    "# Compute the testing accuracy\n",
    "# Set batch size\n",
    "batch_size = 200  # Adjust based on available memory\n",
    "\n",
    "# Initialize list to store correct predictions\n",
    "num_test_correct = []\n",
    "y_pred_total = []\n",
    "\n",
    "# Get testing inputs\n",
    "testing_inputs = torch.from_numpy(test_features).float()\n",
    "testing_targets = torch.from_numpy(test_targets).long()\n",
    "\n",
    "# Ensure no gradients are computed\n",
    "with torch.no_grad():\n",
    "    # Loop through the dataset in batches\n",
    "    for i in range(0, len(testing_inputs), batch_size):\n",
    "        # Select the current batch\n",
    "        test_batch_inputs = testing_inputs[i:i + batch_size]\n",
    "        test_batch_targets = testing_targets[i:i + batch_size]\n",
    "\n",
    "        # Apply the model to the current batch\n",
    "        y_pred_batch = model(test_batch_inputs)\n",
    "        y_pred_total.append(y_pred_batch)\n",
    "\n",
    "        # Find the correct predictions for the batch\n",
    "        num_correct = (torch.argmax(y_pred_batch, dim=1) == test_batch_targets).type(torch.FloatTensor)\n",
    "\n",
    "        num_test_correct.append(num_correct)\n",
    "\n",
    "# Concatenate all correct predictions\n",
    "total_correct = torch.cat(num_test_correct)\n",
    "\n",
    "# Calculate the mean accuracy\n",
    "testing_accuracy = total_correct.mean().item()\n",
    "\n",
    "printed_statement = \"Testing Accuracy: {:.2f}%\".format(testing_accuracy * 100)\n",
    "print(printed_statement)\n",
    "with open(\"../results/results.txt\", \"w\") as file:\n",
    "    file.write(printed_statement)\n",
    "    file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95a5fdb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1729149517360,
     "user": {
      "displayName": "Caroline Crooks",
      "userId": "10803179327028008482"
     },
     "user_tz": 420
    },
    "id": "95a5fdb2",
    "outputId": "d6203a84-078d-43e1-831e-6e0a81dbc1f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of pituitary: 98.66666666666667 %\n",
      "Accuracy of notumor: 99.50617283950616 %\n",
      "Accuracy of meningioma: 91.50326797385621 %\n",
      "Accuracy of glioma: 94.33333333333334 %\n"
     ]
    }
   ],
   "source": [
    "# accuracy of each class\n",
    "all_y_pred = torch.cat(y_pred_total)\n",
    "# iterate through list of classes\n",
    "for i in range(4):\n",
    "  # get indexes where the ith class is in the test\n",
    "  testing_input_indexes = np.where(testing_targets == i)\n",
    "  # find the predictions of the model on the testing inputs for those indices\n",
    "  predictions = torch.argmax(all_y_pred[testing_input_indexes], dim=1).numpy()\n",
    "\n",
    "  # get the real predictions in the same order of list\n",
    "  real_targets = testing_targets[testing_input_indexes].numpy()\n",
    "\n",
    "  # get count of where they match\n",
    "  num_correct = np.sum(predictions == real_targets)\n",
    "  total_per_class = len(testing_targets[testing_input_indexes])\n",
    "\n",
    "  # calculate % correct\n",
    "  printed_statement = f\"Accuracy of {classes[i]}: {num_correct / float(total_per_class) * 100} %\"\n",
    "  print(printed_statement)\n",
    "  with open(\"../results/results.txt\", \"a\") as file:\n",
    "    file.write(printed_statement)\n",
    "    file.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d3d408e-dcbd-4745-b408-a52fcd2fef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
