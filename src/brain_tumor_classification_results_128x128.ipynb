{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835b6358",
   "metadata": {
    "id": "835b6358"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a73760",
   "metadata": {
    "id": "04a73760"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image # For displaying images in colab jupyter cell\n",
    "from PIL import Image as PilImage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc1fbb",
   "metadata": {
    "id": "9dcc1fbb"
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dfa7da9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1729149007409,
     "user": {
      "displayName": "Caroline Crooks",
      "userId": "10803179327028008482"
     },
     "user_tz": 420
    },
    "id": "5dfa7da9",
    "outputId": "0bc26771-8cee-4adc-d02a-d8a52b612e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape:  (5712, 128, 128)\n",
      "Training Targets Shape:  (5712,)\n",
      "Testing Features Shape:  (1311, 128, 128)\n",
      "Testing Targets Shape:  (1311,)\n"
     ]
    }
   ],
   "source": [
    "# Load images\n",
    "\n",
    "# training features/targets where each feature is a greyscale image with shape (512, 512)\n",
    "classes = [\"pituitary\", \"notumor\", \"meningioma\", \"glioma\"]\n",
    "train_folder = \"../data/Training\"\n",
    "test_folder = \"../data/Testing\"\n",
    "\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "# load image from a folder\n",
    "def load_image(folder_path):\n",
    "    features = []\n",
    "    targets = []\n",
    "    for index, class_label in enumerate(classes):\n",
    "        class_folder = os.path.join(folder_path, class_label)\n",
    "        for img_name in os.listdir(class_folder):\n",
    "            img_path = os.path.join(class_folder, img_name)\n",
    "            #print(img_path)\n",
    "            try:\n",
    "                img = PilImage.open(img_path).convert(\"L\")\n",
    "                img = img.resize((img_height,img_width))\n",
    "                img_array = np.array(img)\n",
    "                features.append(img_array)\n",
    "                targets.append(index)\n",
    "            except Exception as e:\n",
    "                print(\"Error loading image \", e)\n",
    "    return np.array(features), np.array(targets)\n",
    "\n",
    "# load images\n",
    "train_features, train_targets = load_image(train_folder)\n",
    "test_features, test_targets = load_image(test_folder)\n",
    "\n",
    "# shapes of training/testing datasets\n",
    "print(\"Training Features Shape: \", train_features.shape)\n",
    "print(\"Training Targets Shape: \", train_targets.shape)\n",
    "print(\"Testing Features Shape: \", test_features.shape)\n",
    "print(\"Testing Targets Shape: \", test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c1e6ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 1837,
     "status": "ok",
     "timestamp": 1729149009239,
     "user": {
      "displayName": "Caroline Crooks",
      "userId": "10803179327028008482"
     },
     "user_tz": 420
    },
    "id": "25c1e6ec",
    "outputId": "f688e6ff-9417-4714-db0d-0c6ae20e8a6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21e938fda90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the first three training features (samples)\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(train_features[0], cmap = 'Greys')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(train_features[1], cmap = 'Greys')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(train_features[2], cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9be3f7",
   "metadata": {
    "id": "ac9be3f7"
   },
   "outputs": [],
   "source": [
    "# perform standard scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# First flatten each image into 512*512 to convert features from 3D -> 2D arrays\n",
    "train_features_flat = train_features.reshape((5712, img_width*img_height))\n",
    "test_features_flat = test_features.reshape((1311, img_width*img_height))\n",
    "\n",
    "# Use standard scaler to scale the flattened images\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features_flat).reshape((5712, img_width*img_height))\n",
    "test_features = scaler.fit_transform(test_features_flat).reshape((1311, img_width*img_height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2025caf",
   "metadata": {
    "id": "a2025caf",
    "outputId": "c80b5499-709a-41e9-a1d9-48d804c65d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape:  (5712, 16384)\n",
      "Training Targets Shape:  (5712,)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle training set\n",
    "import random\n",
    "features_and_targets = list(zip(train_features, train_targets))\n",
    "random.shuffle(features_and_targets)\n",
    "train_features, train_targets = zip(*features_and_targets)\n",
    "train_features = np.array(list(train_features))\n",
    "train_targets = np.array(list(train_targets))\n",
    "print(\"Training Features Shape: \", train_features.shape)\n",
    "print(\"Training Targets Shape: \", train_targets.shape)\n",
    "\n",
    "# Take the first num_validation training features and targets as validation set\n",
    "num_validation = 500\n",
    "num_training = 5712 - 500\n",
    "num_testing = 1311\n",
    "validation_features = train_features[:num_validation]\n",
    "validation_targets = train_targets[:num_validation]\n",
    "\n",
    "# Take the remaining training features and targets as training set\n",
    "train_features = train_features[num_validation:]\n",
    "train_targets = train_targets[num_validation:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8f2369",
   "metadata": {
    "id": "8c8f2369"
   },
   "outputs": [],
   "source": [
    "# Reshape train/validation/test sets to conform to PyTorch's (N, Channels, Height, Width) standard for CNNs\n",
    "train_features = np.reshape(train_features, (num_training, 1, img_width, img_height))\n",
    "validation_features = np.reshape(validation_features, (num_validation, 1, img_width, img_height))\n",
    "test_features = np.reshape(test_features, (num_testing, 1, img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ac541",
   "metadata": {
    "id": "9b3ac541"
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8355384",
   "metadata": {
    "id": "c8355384"
   },
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # Second convolution layer with 16 out channels, 1 padding\n",
    "        self.cnn1 = torch.nn.Conv2d(in_channels=1, out_channels=16,\n",
    "                              kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # normalization for statbility\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(16)\n",
    "\n",
    "        # size 2 kernel for maxpool\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second convolution layer with 32 out channels, 1 padding\n",
    "        self.cnn2 = torch.nn.Conv2d(in_channels=16, out_channels=32,\n",
    "                              kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # normalization for statbility\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # size 2 kernel for maxpool\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Third convolution layer with 64 out channels, 1 padding\n",
    "        self.cnn3 = torch.nn.Conv2d(in_channels=32, out_channels=64,\n",
    "                              kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # normalization for statbility\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        # size 2 kernel for maxpool\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Fully connected layer that takes the flattened output\n",
    "        self.fc2 = torch.nn.Linear(64 * 16 * 16, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # input image -> conv1 -> relu -> batchnorm -> maxpool1\n",
    "        conv1_out = torch.nn.functional.relu(self.cnn1(x))\n",
    "        pool1_out = self.maxpool1(self.batchnorm1(conv1_out))\n",
    "\n",
    "        # maxpool1 output -> conv2 -> relu -> batchnorm -> maxpool2\n",
    "        conv2_out = torch.nn.functional.relu(self.cnn2(pool1_out))\n",
    "        pool2_out = self.maxpool2(self.batchnorm2(conv2_out))\n",
    "\n",
    "        # maxpool2 output -> conv3 -> relu -> batchnorm -> maxpool3\n",
    "        conv3_out = torch.nn.functional.relu(self.cnn3(pool2_out))\n",
    "        pool3_out = self.maxpool3(self.batchnorm3(conv3_out))\n",
    "\n",
    "        # flatten the maxpool3 output to be used as input into FCN layer\n",
    "        fcn_input = pool3_out.view(pool3_out.size(0), -1)\n",
    "\n",
    "        # Use the raw output of the fully connected layer as the final output\n",
    "        out = self.fc2(fcn_input)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9624830",
   "metadata": {
    "id": "b9624830"
   },
   "source": [
    "## Select Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d668a01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729149009628,
     "user": {
      "displayName": "Caroline Crooks",
      "userId": "10803179327028008482"
     },
     "user_tz": 420
    },
    "id": "1d668a01",
    "outputId": "52714af3-5056-487c-fad6-61f640736a4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (cnn1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (cnn2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (cnn3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc2): Linear(in_features=16384, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix the random seed so that model performance is reproducible\n",
    "torch.manual_seed(55)\n",
    "\n",
    "# Initialize CNN model\n",
    "model = CNNModel()\n",
    "\n",
    "# Define learning rate, epoch and batchsize for mini-batch gradient\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batchsize = 75\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3045df",
   "metadata": {
    "id": "9c3045df"
   },
   "source": [
    "## Identify Tracked Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "638259ed",
   "metadata": {
    "id": "638259ed"
   },
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "validation_accuracy_list = np.zeros((epochs,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fbc523",
   "metadata": {
    "id": "a1fbc523"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5f590",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 505511,
     "status": "ok",
     "timestamp": 1729149515133,
     "user": {
      "displayName": "Caroline Crooks",
      "userId": "10803179327028008482"
     },
     "user_tz": 420
    },
    "id": "02a5f590",
    "outputId": "9cb01702-e0c7-48d9-b147-7c768b992000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Validation Accuracy: 89.0%\n",
      "Epoch: 1 Validation Accuracy: 92.0%\n",
      "Epoch: 2 Validation Accuracy: 91.4%\n",
      "Epoch: 3 Validation Accuracy: 91.0%\n",
      "Epoch: 4 Validation Accuracy: 91.6%\n",
      "Epoch: 5 Validation Accuracy: 93.2%\n",
      "Epoch: 6 Validation Accuracy: 93.4%\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# Convert the training, validation, testing dataset (NumPy arrays) into torch tensors\n",
    "train_inputs = torch.from_numpy(train_features).float()\n",
    "train_targets = torch.from_numpy(train_targets).long()\n",
    "\n",
    "validation_inputs = torch.from_numpy(validation_features).float()\n",
    "validation_targets = torch.from_numpy(validation_targets).long()\n",
    "\n",
    "testing_inputs = torch.from_numpy(test_features).float()\n",
    "testing_targets = torch.from_numpy(test_targets).long()\n",
    "\n",
    "# split into batches\n",
    "train_batches_features = torch.split(train_inputs, batchsize)\n",
    "train_batches_targets = torch.split(train_targets, batchsize)\n",
    "\n",
    "batch_split_num = len(train_batches_features)\n",
    "\n",
    "# Training Loop ---------------------------------------------------------------------------------------\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #iteratae through the batches\n",
    "    for k in range(batch_split_num):\n",
    "        # typical training cycle: reset optimizer -> train -> find loss ->\n",
    "        # append loss -> backwards step -> optimizer steps\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_batch_outputs = model(train_batches_features[k])\n",
    "\n",
    "        loss = loss_func(train_batch_outputs, train_batches_targets[k])\n",
    "\n",
    "        train_loss_list.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute Validation Accuracy ----------------------------------------------------------------------\n",
    "    with torch.no_grad():\n",
    "        # apply model\n",
    "        validation_outputs = model(validation_inputs)\n",
    "\n",
    "        # find most probable class with argmax\n",
    "        correct = (torch.argmax(validation_outputs, dim=1) ==\n",
    "                   validation_targets).type(torch.FloatTensor)\n",
    "\n",
    "        print(\"Epoch: \"+ str(epoch),\n",
    "              \"Validation Accuracy: \" + str(np.round(correct.mean().numpy() * 100, 2))\n",
    "              + '%', flush=True)\n",
    "\n",
    "        validation_accuracy_list[epoch] = correct.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf9a22e",
   "metadata": {
    "id": "adf9a22e"
   },
   "source": [
    "## Visualize & Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0863f",
   "metadata": {
    "id": "3bc0863f"
   },
   "outputs": [],
   "source": [
    "# Seaborn for prettier plot\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style = 'whitegrid', font_scale = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f333c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "executionInfo": {
     "elapsed": 699,
     "status": "ok",
     "timestamp": 1729149515826,
     "user": {
      "displayName": "Caroline Crooks",
      "userId": "10803179327028008482"
     },
     "user_tz": 420
    },
    "id": "b23f333c",
    "outputId": "3d6e89e8-eb0a-4809-aad5-4a5b2453ba78"
   },
   "outputs": [],
   "source": [
    "# Visualize training loss\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss_list, linewidth=3, label=\"Training Loss\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "\n",
    "# Validation Accuracy\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(validation_accuracy_list, linewidth=3, color='gold', label=\"Validation Accuracy\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8589b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1537,
     "status": "ok",
     "timestamp": 1729149517360,
     "user": {
      "displayName": "Caroline Crooks",
      "userId": "10803179327028008482"
     },
     "user_tz": 420
    },
    "id": "ee8589b6",
    "outputId": "eb6e0f7f-eeae-464b-941a-74b4ef32ebf3"
   },
   "outputs": [],
   "source": [
    "# Compute the testing accuracy\n",
    "# Set batch size\n",
    "batch_size = 200  # Adjust based on available memory\n",
    "\n",
    "# Initialize list to store correct predictions\n",
    "num_test_correct = []\n",
    "y_pred_total = []\n",
    "\n",
    "# Ensure no gradients are computed\n",
    "with torch.no_grad():\n",
    "    # Loop through the dataset in batches\n",
    "    for i in range(0, len(testing_inputs), batch_size):\n",
    "        # Select the current batch\n",
    "        test_batch_inputs = testing_inputs[i:i + batch_size]\n",
    "        test_batch_targets = testing_targets[i:i + batch_size]\n",
    "\n",
    "        # Apply the model to the current batch\n",
    "        y_pred_batch = model(test_batch_inputs)\n",
    "        y_pred_total.append(y_pred_batch)\n",
    "\n",
    "        # Find the correct predictions for the batch\n",
    "        num_correct = (torch.argmax(y_pred_batch, dim=1) == test_batch_targets).type(torch.FloatTensor)\n",
    "\n",
    "        num_test_correct.append(num_correct)\n",
    "\n",
    "# Concatenate all correct predictions\n",
    "total_correct = torch.cat(num_test_correct)\n",
    "\n",
    "# Calculate the mean accuracy\n",
    "testing_accuracy = total_correct.mean().item()\n",
    "\n",
    "print(\"Testing Accuracy: {:.2f}%\".format(testing_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5fdb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1729149517360,
     "user": {
      "displayName": "Caroline Crooks",
      "userId": "10803179327028008482"
     },
     "user_tz": 420
    },
    "id": "95a5fdb2",
    "outputId": "d6203a84-078d-43e1-831e-6e0a81dbc1f2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy of each class\n",
    "all_y_pred = torch.cat(y_pred_total)\n",
    "# iterate through list of classes\n",
    "for i in range(4):\n",
    "  # get indexes where the ith class is in the test\n",
    "  testing_input_indexes = np.where(testing_targets == i)\n",
    "  # find the predictions of the model on the testing inputs for those indices\n",
    "  predictions = torch.argmax(all_y_pred[testing_input_indexes], dim=1).numpy()\n",
    "\n",
    "  # get the real predictions in the same order of list\n",
    "  real_targets = testing_targets[testing_input_indexes].numpy()\n",
    "\n",
    "  # get count of where they match\n",
    "  num_correct = np.sum(predictions == real_targets)\n",
    "  total_per_class = len(testing_targets[testing_input_indexes])\n",
    "\n",
    "  # calculate % correct\n",
    "  print(\"Accuracy of\", classes[i] + \":\", num_correct/float(total_per_class) * 100, \" %\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
